{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federal Polling Average\n",
    "\n",
    "This is the polling averaging model behind the [cdnpo.li](https://cdnpo.li) website.\n",
    "\n",
    "### Data Processing\n",
    "The data for this is open source, on GitHub. However, some pre-processing is required. First, we need to convert the ratio of new polling data. This is done through `apply_fraction`. Note that this should probably be replaced at some point by a method to only record the most recent of previous polls and otherwise dropping their weights to `0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import locale\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# \"1,000 (1/4)\" = 250\n",
    "def apply_fraction(s):\n",
    "    if isinstance(s, int):\n",
    "        return s\n",
    "    if isinstance(s, float):\n",
    "        if np.isnan(s):\n",
    "            return 100\n",
    "        return int(s)\n",
    "    split = s.split()\n",
    "    sample = int(split[0].replace(',', ''))\n",
    "    regex = r\"\\/\\d\"\n",
    "    if len(split) > 1:\n",
    "        sample /= int(re.findall(regex, split[1])[0].replace(\"/\", \"\"))\n",
    "    return int(sample)\n",
    "\n",
    "def parse_margin(s):\n",
    "    if isinstance(s, float):\n",
    "        return s\n",
    "    trimmed = s.replace('Â±', '')\n",
    "    split = trimmed.split()\n",
    "    try:\n",
    "        return float(split[0])\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def sort_margin_fraction(df):\n",
    "    df = df.replace('-', np.nan)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
    "    df['Margin'] = df['Margin'].apply(lambda x: parse_margin(x))\n",
    "    df['Sample'] = df['Sample'].apply(lambda s: apply_fraction(s))\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    df.index = df['Date']\n",
    "    return df\n",
    "\n",
    "#df2008 = sort_margin_fraction(pd.read_csv(\"https://raw.githubusercontent.com/ErikPartridge/canadian-election-data/master/federal/2008%20Federal%20Polling.csv\"))\n",
    "#df2011 = sort_margin_fraction(pd.read_csv(\"https://raw.githubusercontent.com/ErikPartridge/canadian-election-data/master/federal/2011%20Federal%20Polling.csv\"))\n",
    "df2015 = sort_margin_fraction(pd.read_csv(\"https://raw.githubusercontent.com/ErikPartridge/canadian-election-data/master/federal/2015%20Federal%20Polling.csv\"))\n",
    "df2019 = sort_margin_fraction(pd.read_csv(\"https://raw.githubusercontent.com/ErikPartridge/canadian-election-data/master/federal/2019%20Federal%20Polling.csv\"))\n",
    "df_results = pd.read_csv(\"https://raw.githubusercontent.com/ErikPartridge/canadian-election-data/master/federal/2008-2015%20Federal%20Results.csv\")\n",
    "df_combined = sort_margin_fraction(pd.read_csv(\"https://raw.githubusercontent.com/ErikPartridge/canadian-election-data/master/federal/2008-2019%20Federal%20Polling.csv\"))\n",
    "df2019['Date'] = df2019[\"Date\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "We use the expontential weighted moving average to compute the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1285283152857514\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "df2019['alphas'] = (np.log(df2019['Sample'].astype(float)) / np.log(6)) / 30\n",
    "df2015['alphas'] = (np.log(df2015['Sample'].astype(float)) / np.log(6)) / 30\n",
    "print(df2019['alphas'].median())\n",
    "def ewm(arr, alphas):\n",
    "    \"\"\"\n",
    "    Calculate the EMA of an array arr\n",
    "    :param arr: numpy array of floats\n",
    "    :param alpha: float between 0 and 1\n",
    "    :return: numpy array of floats\n",
    "    \"\"\"\n",
    "    # initialise ewm_arr\n",
    "    ewm_arr = np.zeros_like(arr)\n",
    "    ewm_arr[0] = arr[0]\n",
    "    for t in range(1,arr.shape[0]):\n",
    "        ewm_arr[t] = alphas[t]*arr[t] + (1 - alphas[t-1])*ewm_arr[t-1]\n",
    "    return ewm_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            EWM_Liberal  EWM_Conservative    EWM_NDP  EWM_Green    EWM_BQ\n",
      "Date                                                                     \n",
      "2019-03-25    32.957569         37.878450  16.143103        NaN  3.952589\n",
      "2019-03-27    31.266392         36.644434  16.125300        NaN  3.930004\n",
      "2019-03-27    31.103601         37.075782  16.751927        NaN  4.067549\n",
      "2019-03-29    30.700514         35.904989  16.344751        NaN  3.955556\n",
      "2019-04-05    30.936716         35.812029  16.412058        NaN  3.960121\n",
      "Compared to 2015\n",
      "            EWM_Liberal  EWM_Conservative    EWM_NDP  EWM_Green    EWM_BQ\n",
      "Date                                                                     \n",
      "2015-10-17    36.475697         31.428351  22.634243   4.565095  4.573819\n",
      "2015-10-17    35.881739         31.335434  22.226604   4.642995  4.650449\n",
      "2015-10-18    36.049868         31.572887  22.077663   4.802637  4.709312\n",
      "2015-10-18    36.288814         31.105761  21.619596   4.521451  4.844647\n",
      "2015-10-18    36.273756         30.717860  21.163631   4.485785  4.877464\n"
     ]
    }
   ],
   "source": [
    "def apply_ewm(df):\n",
    "    df['EWM_Liberal'] = ewm(df['Liberal'], df['alphas'])\n",
    "    df['EWM_Conservative'] = ewm(df['Conservative'], df['alphas'])\n",
    "    df['EWM_NDP'] = ewm(df['NDP'], df['alphas'])\n",
    "    df['EWM_Green'] = ewm(df['Green'], df['alphas'])\n",
    "    df['EWM_BQ'] = ewm(df['Bloc QC'], df['alphas'])\n",
    "    return df\n",
    "df2019 = apply_ewm(df2019)\n",
    "df2015 = apply_ewm(df2015)\n",
    "print(df2019[['EWM_Liberal', 'EWM_Conservative', 'EWM_NDP', 'EWM_Green', 'EWM_BQ']].tail())\n",
    "print(\"Compared to 2015\")\n",
    "print(df2015[['EWM_Liberal', 'EWM_Conservative', 'EWM_NDP', 'EWM_Green', 'EWM_BQ']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Alpha Equation | Mean Alpha | Error Lib | Error Con | Error NDP | Err Green | Err BQ |\n",
    "|--------------|----------|---------|---------|---------|---------|------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "clf = BayesianRidge()\n",
    "clf.fit(df_results['Conservative'].values.reshape(-1, 1) / 100, df_results['Liberal - Seats'].values.reshape(-1, 1) / 335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62194802])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[0.30676]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e1edb9e322c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_combined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Liberal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "from fbprophet import Prophet\n",
    "\n",
    "df_combined['Date', 'Liberal']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
